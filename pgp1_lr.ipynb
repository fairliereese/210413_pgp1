{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "military-interest",
   "metadata": {},
   "source": [
    "# Analysis of long-read transcriptomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-senegal",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-bunny",
   "metadata": {},
   "source": [
    "Run Minimap2, TranscriptClean, and TALON using `run_talon_tc.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-maple",
   "metadata": {},
   "source": [
    "Create TALON abundance file\n",
    "```bash \n",
    "db=talon/pgp1.db\n",
    "talon_abundance \\\n",
    "    --db $db \\\n",
    "    -a gencode_v29 \\\n",
    "    -b hg38 \\\n",
    "    --o talon/pgp1\n",
    "```\n",
    "\n",
    "Filter novel transcripts for reproducibility\n",
    "```bash\n",
    "db=talon/pgp1.db\n",
    "talon_filter_transcripts \\\n",
    "    --db $db \\\n",
    "    -a gencode_v29 \\\n",
    "    --maxFracA=0.5 \\\n",
    "    --minCount=5 \\\n",
    "    --minDatasets=2 \\\n",
    "    --o talon/pgp1_pass_list.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-chocolate",
   "metadata": {},
   "source": [
    "### TSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-community",
   "metadata": {},
   "source": [
    "Isolate reads that represent more confident 5' ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "affected-mainstream",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fairliereese/miniconda3/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import RangeIndex\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import swan_vis as swan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tutorial-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot = 'talon/pgp1_talon_read_annot.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "spatial-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the reads to those that represent putative 5' ends\n",
    "df = pd.read_csv(annot, sep='\\t')\n",
    "tss_df = df.loc[df.transcript_novelty.isin(['Known', 'NIC', 'NNC', 'ISM'])]\n",
    "tss_df = tss_df.loc[tss_df.ISM_subtype.isin(['None', 'Prefix', 'Both'])]\n",
    "tss_reads = tss_df.read_name.tolist()\n",
    "\n",
    "# tss\n",
    "fname = 'tss_read_names.txt'\n",
    "with open(fname, 'w') as ofile:\n",
    "    for r in tss_reads:\n",
    "        ofile.write(r+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-russia",
   "metadata": {},
   "source": [
    "Create a sam file with all the TSS reads from the merged BAM using picard tools `isolate_tss_reads.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-providence",
   "metadata": {},
   "source": [
    "Call TSSs using Diane's script\n",
    "```bash\n",
    "tss_dir=~/mortazavi_lab/bin/tss-annotation/long_read/\n",
    "python ${tss_dir}pacbio_to_tss.py \\\n",
    "    -i tss_reads.bam \\\n",
    "    --window-size=50 \\\n",
    "    --expression-threshold=2 \\\n",
    "    -o unfilt_tss.bed \\\n",
    "    -r \\\n",
    "    -n rev_tss.bw \\\n",
    "    -p fwd_tss.bw\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-blogger",
   "metadata": {},
   "source": [
    "### Swan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-inspection",
   "metadata": {},
   "source": [
    "Swan config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aware-baseball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding dataset annotation to the SwanGraph\n",
      "\n",
      "Adding dataset astro_1 to the SwanGraph\n",
      "\n",
      "Adding dataset astro_2 to the SwanGraph\n",
      "\n",
      "Adding dataset excite_neuron_1 to the SwanGraph\n",
      "\n",
      "Adding dataset excite_neuron_2 to the SwanGraph\n",
      "\n",
      "Adding dataset pgp1_1 to the SwanGraph\n",
      "\n",
      "Adding dataset pgp1_2 to the SwanGraph\n",
      "Saving graph as swan.p\n"
     ]
    }
   ],
   "source": [
    "annot = '/Users/fairliereese/mortazavi_lab/ref/gencode.v29/gencode.v29.SIRV.ERCC.annotation.gtf'\n",
    "\n",
    "# initialize SwanGraph\n",
    "sg = swan.SwanGraph()\n",
    "\n",
    "# add annotation GTF for reference\n",
    "sg.add_annotation(annot)\n",
    "\n",
    "# add transcript models from each dataset\n",
    "sg.add_datasets('swan_config.tsv')\n",
    "\n",
    "sg.save_graph('swan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-governor",
   "metadata": {},
   "source": [
    "### TSS switching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-conversion",
   "metadata": {},
   "source": [
    "### Isoform switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "thermal-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import anndata\n",
    "import scipy.stats as st\n",
    "import statsmodels.stats as stm\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "historical-publisher",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming to str index.\n",
      "Transforming to str index.\n"
     ]
    }
   ],
   "source": [
    "pass_list = 'talon/pgp1_pass_list.csv'\n",
    "ab_file = 'talon/pgp1_talon_abundance.tsv'\n",
    "cond_map = {'Astrocytes': ['astro_1', 'astro_2'], \\\n",
    "            'Excitatory neurons': ['excite_neuron_1', 'excite_neuron_2'], \\\n",
    "            'PGP1': ['pgp1_1', 'pgp1_2']}\n",
    "adata = make_adata(ab_file, pass_list, cond_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "recent-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_adata(ab_file, pass_list, cond_map):\n",
    "    \n",
    "    # filter talon ab file based on pass list\n",
    "    df = pd.read_csv(ab_file, sep='\\t')\n",
    "    pass_list = pd.read_csv(pass_list, header=None, names=['gene_id', 'transcript_id'])\n",
    "    df = df.loc[df.transcript_ID.isin(pass_list.transcript_id.tolist())]\n",
    "\n",
    "    # obs table\n",
    "    obs = pd.DataFrame.from_dict(cond_map, orient='index')\n",
    "    obs.reset_index(inplace=True)\n",
    "    id_vars = ['index']\n",
    "    value_vars = obs.columns[1:]\n",
    "    obs = obs.melt(id_vars=id_vars, value_vars=value_vars)\n",
    "    obs.drop('variable', axis=1, inplace=True)\n",
    "    obs.rename({'index':'condition', 'value':'dataset'}, axis=1, inplace=True)\n",
    "\n",
    "    # var table\n",
    "    var_cols = ['annot_transcript_id', 'annot_gene_id', \\\n",
    "                 'gene_ID', 'transcript_ID', 'transcript_novelty', \\\n",
    "                 'ISM_subtype']\n",
    "    var = df[var_cols]\n",
    "\n",
    "    # X table\n",
    "    df = df.transpose()\n",
    "    df = df.loc[df.index.isin(obs.dataset.tolist())]\n",
    "    obs_order = obs['dataset'].reset_index().set_index('dataset')\n",
    "    df['dataset_num'] = df.index.map(obs_order['index'])\n",
    "    df.sort_values('dataset_num', inplace=True)\n",
    "    df.drop('dataset_num', axis=1, inplace=True)\n",
    "    X = df.to_numpy()\n",
    "\n",
    "    adata = anndata.AnnData(obs=obs, var=var, X=X) \n",
    "    \n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-looking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
