{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "educational-corrections",
   "metadata": {},
   "source": [
    "# Analysis of long-read transcriptomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "driving-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import anndata\n",
    "import scipy.stats as st\n",
    "import statsmodels.stats as stm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import swan_vis as swan\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib as mpl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-rating",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-singapore",
   "metadata": {},
   "source": [
    "Run Minimap2, TranscriptClean, and TALON using `run_talon_tc.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-vegetable",
   "metadata": {},
   "source": [
    "Create TALON abundance file\n",
    "```bash \n",
    "db=talon/pgp1.db\n",
    "talon_abundance \\\n",
    "    --db $db \\\n",
    "    -a gencode_v29 \\\n",
    "    -b hg38 \\\n",
    "    --o talon/pgp1\n",
    "```\n",
    "\n",
    "Filter novel transcripts for reproducibility\n",
    "```bash\n",
    "db=talon/pgp1.db\n",
    "talon_filter_transcripts \\\n",
    "    --db $db \\\n",
    "    -a gencode_v29 \\\n",
    "    --maxFracA=0.5 \\\n",
    "    --minCount=5 \\\n",
    "    --minDatasets=2 \\\n",
    "    --o talon/pgp1_pass_list.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-shopper",
   "metadata": {},
   "source": [
    "### TSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-corpus",
   "metadata": {},
   "source": [
    "Isolate reads that represent more confident 5' ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "recorded-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import swan_vis as swan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "professional-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot = 'talon/pgp1_talon_read_annot.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incorporated-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the reads to those that represent putative 5' ends\n",
    "df = pd.read_csv(annot, sep='\\t')\n",
    "tss_df = df.loc[df.transcript_novelty.isin(['Known', 'NIC', 'NNC', 'ISM'])]\n",
    "tss_df = tss_df.loc[tss_df.ISM_subtype.isin(['None', 'Prefix', 'Both'])]\n",
    "tss_reads = tss_df.read_name.tolist()\n",
    "\n",
    "# tss\n",
    "fname = 'tss_read_names.txt'\n",
    "with open(fname, 'w') as ofile:\n",
    "    for r in tss_reads:\n",
    "        ofile.write(r+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-apple",
   "metadata": {},
   "source": [
    "Create a sam file with all the TSS reads from the merged BAM using picard tools `isolate_tss_reads.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-norman",
   "metadata": {},
   "source": [
    "Call TSSs using Diane's script\n",
    "```bash\n",
    "tss_dir=~/mortazavi_lab/bin/tss-annotation/long_read/\n",
    "python ${tss_dir}pacbio_to_tss.py \\\n",
    "    -i tss_reads.bam \\\n",
    "    --window-size=50 \\\n",
    "    --expression-threshold=2 \\\n",
    "    -o unfilt_tss.bed \\\n",
    "    -r \\\n",
    "    -n rev_tss.bw \\\n",
    "    -p fwd_tss.bw\n",
    "```\n",
    "\n",
    "Get the read names associated with each TSS as well \n",
    "```bash\n",
    "python ${tss_dir}tss_reads.py \\\n",
    "    -i talon_tmp/merged.bam \\\n",
    "    -r unfilt_tss.bed \\\n",
    "    -o tss_reads.bed\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recent-stage",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-70a29921bd60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# print(len(df.index))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m ends = pd.read_csv(tss_reads, sep='\\t', header=None,\n\u001b[0;32m---> 14\u001b[0;31m             names=['chrom', 'start', 'end', 'read_name', 'tss_id', 'stand'])\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# merge on read name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2145\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2146\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \"\"\"\n\u001b[1;32m    532\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# filter a list of TSSs for each gene\n",
    "annot = 'talon/pgp1_talon_read_annot.tsv'\n",
    "tss_reads = 'tss_reads.bed'\n",
    "\n",
    "df = pd.read_csv(annot, sep='\\t')\n",
    "\n",
    "# remove sirvs and erccs\n",
    "df = df.loc[~df.chrom.str.contains('SIRV')]\n",
    "df = df.loc[~df.chrom.str.contains('ERCC')]\n",
    "\n",
    "# print('Before assigning each read a TSS')\n",
    "# print(len(df.index))\n",
    "ends = pd.read_csv(tss_reads, sep='\\t', header=None,\n",
    "            names=['chrom', 'start', 'end', 'read_name', 'tss_id', 'stand'])\n",
    "\n",
    "# merge on read name\n",
    "df = df.merge(ends, how='inner', on='read_name')\n",
    "\n",
    "# groupby on gene and tss\n",
    "df = df[['read_name', 'annot_gene_name', 'tss_id']].groupby(['annot_gene_name', 'tss_id']).count()\n",
    "\n",
    "# filter tsss for those that have >10% of the reads\n",
    "# for the most highly-expressed tss of the gene\n",
    "df.reset_index(inplace=True)\n",
    "df.rename({'read_name':'count'}, axis=1, inplace=True)\n",
    "temp = df.loc[df.apply(lambda x: x['count'] >= df.loc[df.annot_gene_name==x.annot_gene_name, 'count'].max()*0.1, axis=1)]\n",
    "\n",
    "temp.loc[temp.annot_gene_name == 'MBP']\n",
    "\n",
    "#, assign each TSS a name, and quantify TSS exp\n",
    "temp.sort_values(by=['annot_gene_name'], inplace=True)\n",
    "temp['tss_id_2'] = np.nan\n",
    "prev_gene = None\n",
    "for ind, entry in temp.iterrows():\n",
    "    curr_gene = entry.annot_gene_name\n",
    "    if curr_gene != prev_gene:\n",
    "        i = 1\n",
    "    else:\n",
    "        i += 1\n",
    "    prev_gene = curr_gene\n",
    "    temp.loc[ind, 'tss_id_2'] = '{}_{}'.format(curr_gene, i)\n",
    "    \n",
    "# merged called TSSs back in with read annot\n",
    "df = pd.read_csv(annot, sep='\\t')\n",
    "ends = pd.read_csv(tss_reads, sep='\\t', header=None,\n",
    "            names=['chrom', 'start', 'end', 'read_name', 'tss_id', 'stand'])\n",
    "ends = ends[['read_name', 'tss_id']]\n",
    "\n",
    "# merge on read name\n",
    "df = df.merge(ends, how='inner', on='read_name')\n",
    "temp = temp[['annot_gene_name', 'tss_id', 'tss_id_2']]\n",
    "df = df.merge(temp, how='inner', on=['annot_gene_name', 'tss_id'])\n",
    "\n",
    "# format like talon ab\n",
    "cols = ['annot_gene_name', 'annot_gene_id', 'dataset', 'tss_id_2']\n",
    "df = df[cols+['read_name']].groupby(cols).count().reset_index()\n",
    "df.rename({'read_name':'counts', 'tss_id_2':'tss_id'}, axis=1, inplace=True)\n",
    "df = df.pivot(index=['annot_gene_name', 'annot_gene_id', 'tss_id'], columns='dataset', values='counts')\n",
    "df.reset_index(inplace=True)\n",
    "df = df.rename_axis(None, axis=1)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# i guess sum over genes with the same name smh\n",
    "df.drop('annot_gene_id', axis=1, inplace=True)\n",
    "df = df.groupby(['annot_gene_name', 'tss_id']).sum().reset_index()\n",
    "\n",
    "print(len(df.index))\n",
    "print(len(df.columns))\n",
    "df.to_csv('pgp1_tss_talon_abundance.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-sweden",
   "metadata": {},
   "source": [
    "### Swan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-grace",
   "metadata": {},
   "source": [
    "Swan config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "happy-blair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding dataset annotation to the SwanGraph\n",
      "\n",
      "Adding dataset astro_1 to the SwanGraph\n",
      "\n",
      "Adding dataset astro_2 to the SwanGraph\n",
      "\n",
      "Adding dataset excite_neuron_1 to the SwanGraph\n",
      "\n",
      "Adding dataset excite_neuron_2 to the SwanGraph\n",
      "\n",
      "Adding dataset pgp1_1 to the SwanGraph\n",
      "\n",
      "Adding dataset pgp1_2 to the SwanGraph\n",
      "Saving graph as swan.p\n"
     ]
    }
   ],
   "source": [
    "annot = '/Users/fairliereese/mortazavi_lab/ref/gencode.v29/gencode.v29.SIRV.ERCC.annotation.gtf'\n",
    "\n",
    "# initialize SwanGraph\n",
    "sg = swan.SwanGraph()\n",
    "\n",
    "# add annotation GTF for reference\n",
    "sg.add_annotation(annot)\n",
    "\n",
    "# add transcript models from each dataset\n",
    "sg.add_datasets('swan_config.tsv')\n",
    "\n",
    "sg.save_graph('swan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "skilled-budget",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 752 intronic edges for ES\n",
      "Found 231 novel es events in 259 transcripts.\n",
      "Analyzing 2184 exonic edges for IR\n",
      "Found 65 novel ir events from 71 transcripts.\n"
     ]
    }
   ],
   "source": [
    "# detect IR and ES\n",
    "g_es, t_es, e_es = sg.find_es_genes()\n",
    "g_ir, t_ir, e_ir = sg.find_ir_genes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-sweden",
   "metadata": {},
   "source": [
    "### TSS switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "secondary-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df: talon abundance file (either tss or transcript)\n",
    "# cond_map: dictionary of {condition: [dataset1, dataset2]}; how you want to group datasets\n",
    "# how: whether to make a tss or iso level adata; 'tss' or 'iso'\n",
    "# pass_list: if 'iso', file of valid transcript IDs that pass filtering\n",
    "def make_adata(df, cond_map, how='iso', pass_list=None):\n",
    "    \n",
    "    # filter talon ab file based on pass list\n",
    "#     df = pd.read_csv(ab_file, sep='\\t')\n",
    "    if pass_list:\n",
    "        pass_list = pd.read_csv(pass_list, header=None, names=['gene_id', 'transcript_id'])\n",
    "        df = df.loc[df.transcript_ID.isin(pass_list.transcript_id.tolist())]\n",
    "\n",
    "    # obs table\n",
    "    obs = pd.DataFrame.from_dict(cond_map, orient='index')\n",
    "    obs.reset_index(inplace=True)\n",
    "    id_vars = ['index']\n",
    "    value_vars = obs.columns[1:]\n",
    "    obs = obs.melt(id_vars=id_vars, value_vars=value_vars)\n",
    "    obs.drop('variable', axis=1, inplace=True)\n",
    "    obs.rename({'index':'condition', 'value':'dataset'}, axis=1, inplace=True)\n",
    "\n",
    "    # var table\n",
    "    if how=='iso':\n",
    "        var_cols = ['annot_transcript_name', 'annot_gene_name',\\\n",
    "                    'annot_transcript_id', 'annot_gene_id', \\\n",
    "                    'gene_ID', 'transcript_ID', 'transcript_novelty', \\\n",
    "                    'ISM_subtype']\n",
    "        var = df[var_cols]\n",
    "        var.rename({'transcript_ID':'transcript_id', \\\n",
    "                    'gene_ID':'gene_id',\\\n",
    "                    'annot_gene_name': 'gene_name'}, axis=1, inplace=True)\n",
    "    if how=='tss': \n",
    "        var_cols = ['annot_gene_name', 'tss_id']\n",
    "        var = df[var_cols]\n",
    "        var.rename({'annot_gene_name': 'gene_name'}, axis=1, inplace=True)\n",
    "        \n",
    "    # X table\n",
    "    df = df.transpose()\n",
    "    df = df.loc[df.index.isin(obs.dataset.tolist())]\n",
    "    obs_order = obs['dataset'].reset_index().set_index('dataset')\n",
    "    df['dataset_num'] = df.index.map(obs_order['index'])\n",
    "    df.sort_values('dataset_num', inplace=True)\n",
    "    df.drop('dataset_num', axis=1, inplace=True)\n",
    "    X = df.to_numpy()\n",
    "\n",
    "    adata = anndata.AnnData(obs=obs, var=var, X=X) \n",
    "    \n",
    "    return adata\n",
    "\n",
    "# gene_df: pandas dataframe with expression values in each condition for each TSS in a gene\n",
    "# conditions: list of str of condition names\n",
    "# rc: threshold of read count per gene in each condition necessary to test this gene\n",
    "def test_gene(gene_df, conditions, col, id_col, rc=10):\n",
    "    \n",
    "    gene_df = gene_df.pivot(index=col, columns=id_col, values='counts')\n",
    "    gene_df = gene_df.transpose()\n",
    "    \n",
    "    groups = gene_df.columns.tolist()\n",
    "    gene_df['total_counts'] = gene_df[groups].sum(axis=1)\n",
    "    gene_df.sort_values(by='total_counts', ascending=False, inplace=True)\n",
    "\n",
    "    if len(gene_df.index) > 11:\n",
    "        gene_df.reset_index(inplace=True)\n",
    "\n",
    "        beep = gene_df.iloc[10:].sum()\n",
    "        beep[id_col] = 'all_other'\n",
    "        beep.index.name = None  \n",
    "        beep = pd.DataFrame(beep).transpose()\n",
    "\n",
    "        gene_df = gene_df.iloc[:10]\n",
    "        gene_df = pd.concat([gene_df, beep])  \n",
    "        \n",
    "    # limit to just isoforms with > 0 expression in both conditions\n",
    "    cond1 = conditions[0]\n",
    "    cond2 = conditions[1]\n",
    "    gene_df = gene_df.loc[(gene_df[cond1]>0)&(gene_df[cond2]>0)]\n",
    "    \n",
    "    # does this gene reach the desired read count threshold?\n",
    "    for cond in conditions:\n",
    "        if gene_df[cond].sum() < rc:\n",
    "            return np.nan, np.nan\n",
    "    \n",
    "    # only do the rest if there's nothing left\n",
    "    if gene_df.empty:\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    # calculate the percent of each sample each TSS accounts for\n",
    "    cond_pis = []\n",
    "    for cond in conditions:\n",
    "        total_col = '{}_total'.format(cond)\n",
    "        pi_col = '{}_pi'.format(cond)\n",
    "        total_count = gene_df[cond].sum()\n",
    "\n",
    "        cond_pis.append(pi_col)\n",
    "\n",
    "        gene_df[total_col] = total_count\n",
    "        gene_df[pi_col] = (gene_df[cond]/gene_df[total_col])*100\n",
    "        \n",
    "    # compute isoform-level and gene-level delta pis\n",
    "    gene_df['dpi'] = gene_df[cond_pis[0]] - gene_df[cond_pis[1]]\n",
    "    gene_df['abs_dpi'] = gene_df.dpi.abs()\n",
    "    gene_dpi = gene_df.iloc[:2].abs_dpi.sum()    \n",
    "    \n",
    "    # chi squared test \n",
    "    chi_table = gene_df[conditions].to_numpy()\n",
    "    chi2, p, dof, exp = st.chi2_contingency(chi_table)\n",
    "    \n",
    "    return p, gene_dpi\n",
    "\n",
    "def filter_die_results(df, p, dpi):\n",
    "    df = df.loc[(df.adj_p_val<=p)&(df.dpi>=dpi)]\n",
    "    return df\n",
    "\n",
    "# adata: adata with TSS or iso expression \n",
    "# conditions: len 2 list of strings of conditions to compare\n",
    "# col: string, which column the condition labels are in\n",
    "# how: 'tss' or 'iso'\n",
    "def get_die(adata, conditions, how='tss', rc=15):\n",
    "    \n",
    "    if how == 'tss':\n",
    "        id_col = 'tss_id'\n",
    "    elif how == 'iso':\n",
    "        id_col = 'transcript_id'\n",
    "    \n",
    "    # make df that we can groupby\n",
    "    col = 'condition'\n",
    "    colnames = adata.var[id_col].tolist()\n",
    "    rownames = adata.obs.dataset.tolist()    \n",
    "    raw = adata.X\n",
    "    df = pd.DataFrame(data=raw, index=rownames, columns=colnames)\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename({'index':'dataset'}, axis=1, inplace=True)\n",
    "    samp = adata.obs[['dataset', col]]\n",
    "    df = df.merge(samp, how='left', on='dataset')\n",
    "    \n",
    "    # limit to only the samples that we want in this condition\n",
    "    df[col] = df[col].astype('str')\n",
    "    df = df.loc[df[col].isin(conditions)]\n",
    "        \n",
    "    # groupby sample type and sum over gen\n",
    "    df.drop('dataset', axis=1, inplace=True)\n",
    "    df = df.groupby(col).sum().reset_index()\n",
    "    \n",
    "    # melty boi\n",
    "    tss_cols = df.columns.tolist()[1:]\n",
    "    df = df.melt(id_vars=col, value_vars=tss_cols)\n",
    "    \n",
    "    # rename some cols\n",
    "    df.rename({'variable':id_col,'value':'counts'}, axis=1, inplace=True)\n",
    "    \n",
    "    # merge with gene names\n",
    "    df = df.merge(adata.var, how='left', on=id_col)\n",
    "    \n",
    "    # get total number of tss or iso / gene\n",
    "    bop = df[['gene_name', id_col]].groupby('gene_name').count().reset_index()\n",
    "    \n",
    "    # construct tables for each gene and test!\n",
    "    gene_names = df.gene_name.unique().tolist()\n",
    "    gene_de_df = pd.DataFrame(index=gene_names, columns=['p_val', 'dpi'], data=[[np.nan for i in range(2)] for j in range(len(gene_names))])\n",
    "    for gene in gene_names:\n",
    "        gene_df = df.loc[df.gene_name==gene]\n",
    "        p, dpi = test_gene(gene_df, conditions, col, id_col, rc=rc)\n",
    "        gene_de_df.loc[gene, 'p_val'] = p\n",
    "        gene_de_df.loc[gene, 'dpi'] = dpi\n",
    "        \n",
    "    # correct p values \n",
    "    gene_de_df.dropna(axis=0, inplace=True)\n",
    "    p_vals = gene_de_df.p_val.tolist()\n",
    "    _, adj_p_vals, _, _ = multipletests(p_vals, method='fdr_bh')\n",
    "    gene_de_df['adj_p_val'] = adj_p_vals\n",
    "    \n",
    "    gene_de_df.reset_index(inplace=True)\n",
    "    \n",
    "    return gene_de_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "presidential-apartment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fairliereese/miniconda3/lib/python3.7/site-packages/pandas/core/frame.py:4303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "Transforming to str index.\n",
      "Transforming to str index.\n"
     ]
    }
   ],
   "source": [
    "ab_file = 'talon/pgp1_tss_talon_abundance.tsv'\n",
    "cond_map = {'Astrocytes': ['astro_1', 'astro_2'], \\\n",
    "            'Excitatory neurons': ['excite_neuron_1', 'excite_neuron_2'], \\\n",
    "            'PGP1': ['pgp1_1', 'pgp1_2']}\n",
    "\n",
    "df = pd.read_csv(ab_file, sep='\\t')\n",
    "adata = make_adata(df, cond_map, how='tss')\n",
    "\n",
    "# do one test for each pair of conditions\n",
    "tested = []\n",
    "conditions = ['Astrocytes', 'Excitatory neurons', 'PGP1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interior-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "how = 'tss'\n",
    "for c1 in conditions:\n",
    "    for c2 in conditions: \n",
    "        if (c1, c2) in tested or c1 == c2 or (c2, c1) in tested:\n",
    "            continue\n",
    "        else:\n",
    "            tested.append((c1,c2))\n",
    "        df = get_die(adata, [c1, c2], how=how, rc=10)\n",
    "        fname = '{}_{}_{}_die.tsv'.format(c1, c2, how)\n",
    "        df.to_csv(fname, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "outside-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "tested = []\n",
    "p = 0.05\n",
    "dpi = 10\n",
    "how = 'tss'\n",
    "conditions = ['Astrocytes', 'Excitatory neurons', 'PGP1']\n",
    "for c1 in conditions:\n",
    "    for c2 in conditions: \n",
    "        if (c1, c2) in tested or c1 == c2 or (c2, c1) in tested:\n",
    "            continue\n",
    "        else:\n",
    "            tested.append((c1,c2))\n",
    "        fname = '{}_{}_{}_die.tsv'.format(c1, c2, how)\n",
    "        df = pd.read_csv(fname, sep='\\t')\n",
    "        df = filter_die_results(df, p, dpi)\n",
    "        fname = '{}_{}_{}_sig_die.tsv'.format(c1, c2, how)\n",
    "        df.to_csv(fname, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "deadly-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cond_map(groups, group_names):\n",
    "    cond_map = dict()\n",
    "    \n",
    "    print(groups)\n",
    "    print(group_names)\n",
    "    print()\n",
    "    for group, group_name in zip(groups, group_names):\n",
    "        print(group)\n",
    "        print(group_name)\n",
    "        cond_map[group] = group_name\n",
    "    return cond_map\n",
    "\n",
    "\n",
    "# calculate the normalized average or sum of TSS expression \n",
    "# per cell from the TSS anndata object\n",
    "def calc_exp(adata, groups, group_names, how='tss', cpm=False):\n",
    "    \n",
    "    try:\n",
    "        adata.var.reset_index(inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if how == 'tss':\n",
    "        id_col = 'tss_id'\n",
    "    elif how == 'iso':\n",
    "        id_col = 'transcript_id'\n",
    "        \n",
    "    # conditions map\n",
    "    cond_map = make_cond_map(groups, group_names)\n",
    "    print(cond_map)\n",
    "    col = 'condition'\n",
    "    adata.obs[col] = adata.obs.dataset.map(cond_map)\n",
    "    \n",
    "    # make df that we can groupby\n",
    "    colnames = adata.var[id_col].tolist()\n",
    "    rownames = adata.obs.dataset.tolist()    \n",
    "    raw = adata.X\n",
    "    gene_names = adata.var.gene_name.tolist()\n",
    "    df = pd.DataFrame(data=raw, index=rownames, columns=colnames)\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename({'index':'dataset'}, axis=1, inplace=True)\n",
    "    samp = adata.obs[['dataset', col]]\n",
    "    df = df.merge(samp, how='left', on='dataset')\n",
    "    \n",
    "    # limit to only the cells that we want in this condition\n",
    "    df[col] = df[col].astype('str')\n",
    "    df = df.loc[df[col].isin(group_names)]\n",
    "        \n",
    "    # groupby sample type and sum over gen\n",
    "    df.drop('dataset', axis=1, inplace=True)\n",
    "    df = df.groupby(col).sum().reset_index()\n",
    "    \n",
    "    if cpm:\n",
    "        # since these values haven't been normalized yet, do that\n",
    "        # CPM : (counts/total_counts)* 1**6\n",
    "        # Note : ATAC values were pre-normalized\n",
    "        df.set_index(col, inplace=True)\n",
    "        df = df.transpose()\n",
    "        for c in group_names:\n",
    "            total_counts = df[c].sum()\n",
    "            df[c] = (df[c]/total_counts)*(1^6)\n",
    "        df = df.transpose()\n",
    "        df.reset_index(inplace=True)\n",
    "    \n",
    "    # melty boi\n",
    "    tss_cols = df.columns.tolist()[1:]\n",
    "    df = df.melt(id_vars=col, value_vars=tss_cols)\n",
    "    \n",
    "    # rename some cols\n",
    "    df.rename({'variable':id_col,'value':'counts'}, axis=1, inplace=True)\n",
    "            \n",
    "    # add gene name\n",
    "    if how == 'tss':\n",
    "        temp = adata.var[[id_col, 'gene_name']]\n",
    "    df = df.merge(temp, how='left', on=id_col)\n",
    "\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "narrative-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_colors():\n",
    "    c_dict = {'astro_1': '#f6ef7c', 'astro_2': '#eabc68',\\\n",
    "          'excite_neuron_1': '#e4d3cd', 'excite_neuron_2': '#d3a8b2',\\\n",
    "          'pgp1_1': '#bef4ff', 'pgp1_2': '#73a8b2'}\n",
    "    order = ['pgp1_1', 'pgp1_2', 'astro_1', 'astro_2', 'excite_neuron_1', 'excite_neuron_2']\n",
    "    return c_dict, order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "large-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_cmap():\n",
    "    \n",
    "    # get condition and cluster colors\n",
    "    samp_cdict, _ = get_sample_colors()\n",
    "    \n",
    "    # raw values \n",
    "    samples = ['pgp1_1', 'pgp1_2', 'astro_1', 'astro_2', 'excite_neuron_1', 'excite_neuron_2']\n",
    "    data = np.transpose([samples])\n",
    "    df = pd.DataFrame(data=data, \n",
    "                      columns=['sample'])\n",
    " \n",
    "    # assign arbitrary numbers to each category (cluster, condition)\n",
    "    cats = samples\n",
    "    cat_dict = dict([(cat, i) for i, cat in enumerate(cats)])\n",
    "    df['sample'] = df['sample'].map(cat_dict)\n",
    "    df = df.transpose()\n",
    "    \n",
    "    colors = [samp_cdict[cat] for cat in cats]\n",
    "    cat_cmap = ListedColormap(colors)\n",
    "    \n",
    "    return df, cat_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "embedded-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tss_heatmap(adata, groups, group_names, gname, opref):\n",
    "    \n",
    "    # calculate TSS expression per condition\n",
    "    tss_df = calc_exp(adata, groups, group_names, how='tss')\n",
    "    \n",
    "    # subset by gene and calculate DPI per gene\n",
    "    tss_df = tss_df.loc[tss_df.gene_name == gname]\n",
    "    n_tss = len(tss_df.tss_id.unique())\n",
    "    tss_df.drop(['gene_name'], axis=1, inplace=True)\n",
    "    tss_df = tss_df.pivot(index='tss_id', columns='condition', values='counts')\n",
    "    tss_df = tss_df.div(tss_df.sum(axis=0), axis=1)\n",
    "    \n",
    "    # get categorical colormap\n",
    "    mini_obs, cat_cmap = get_cat_cmap()\n",
    "    \n",
    "    # plot the figure\n",
    "    sns.set(rc={'figure.figsize':(12,7)})\n",
    "    sns.set_context('paper', font_scale=1.5)\n",
    "    fig = plt.figure()\n",
    "    \n",
    "\n",
    "    # complicated subplot stuff\n",
    "    tss_ax = plt.subplot2grid((n_tss+1,1), loc=(0,0), rowspan=n_tss)\n",
    "\n",
    "    # fig, axes = plt.subplots(nrows=4)\n",
    "    fig.subplots_adjust(hspace=0.00)\n",
    "    fig.subplots_adjust(wspace=0.05)\n",
    "\n",
    "    # plot tss only plot\n",
    "    print(tss_df.head())\n",
    "    sns.heatmap(tss_df, cmap='magma', ax=tss_ax, cbar=False)\n",
    "    tss_ax.set_yticklabels(tss_ax.get_yticklabels(), rotation=0)\n",
    "    tss_ax.set_ylabel('')\n",
    "    tss_ax.set_xlabel('')\n",
    "\n",
    "    # plot sample labels\n",
    "    tss_colorbar_ax = fig.add_subplot((n_tss+1)*2,1,((n_tss+1)*2)-1)\n",
    "    sns.heatmap(mini_obs, cmap=cat_cmap,\n",
    "                ax=tss_colorbar_ax, cbar=False)\n",
    "    tss_colorbar_ax.set_ylabel('')\n",
    "    tss_colorbar_ax.set_xlabel('')\n",
    "    tss_colorbar_ax.tick_params(left=False, labelleft=False, rotation=0)\n",
    "    tss_colorbar_ax.tick_params(right=False, labelright=False, rotation=0)\n",
    "    tss_colorbar_ax.set_xticklabels('')\n",
    "\n",
    "    # plot colorbars\n",
    "    tss_colorbar_ax = fig.add_subplot((n_tss+1)*5,1,((n_tss+1)*5)-1)\n",
    "    cmap = plt.get_cmap('magma')\n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "    cb = mpl.colorbar.ColorbarBase(tss_colorbar_ax, cmap=cmap,\n",
    "                                  norm=norm, orientation='horizontal')\n",
    "    cb.set_label('Proportion TSS usage')\n",
    "    \n",
    "    fname = '{}_{}_heatmap.pdf'.format(opref, gname)\n",
    "    plt.savefig(fname, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "vocal-elimination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pgp1_1', 'pgp1_2', 'astro_1', 'astro_2', 'excite_neuron_1', 'excite_neuron_2']\n",
      "['pgp1_1', 'pgp1_2', 'astro_1', 'astro_2', 'excite_neuron_1', 'excite_neuron_2']\n",
      "\n",
      "pgp1_1\n",
      "pgp1_1\n",
      "pgp1_2\n",
      "pgp1_2\n",
      "astro_1\n",
      "astro_1\n",
      "astro_2\n",
      "astro_2\n",
      "excite_neuron_1\n",
      "excite_neuron_1\n",
      "excite_neuron_2\n",
      "excite_neuron_2\n",
      "{'pgp1_1': 'pgp1_1', 'pgp1_2': 'pgp1_2', 'astro_1': 'astro_1', 'astro_2': 'astro_2', 'excite_neuron_1': 'excite_neuron_1', 'excite_neuron_2': 'excite_neuron_2'}\n",
      "condition   astro_1   astro_2  excite_neuron_1  excite_neuron_2  pgp1_1  \\\n",
      "tss_id                                                                    \n",
      "TCF4_1     0.176471  0.000000         0.907407         0.896552  0.0000   \n",
      "TCF4_2     0.352941  0.555556         0.037037         0.051724  0.5625   \n",
      "TCF4_3     0.470588  0.444444         0.055556         0.051724  0.4375   \n",
      "\n",
      "condition    pgp1_2  \n",
      "tss_id               \n",
      "TCF4_1     0.045455  \n",
      "TCF4_2     0.636364  \n",
      "TCF4_3     0.318182  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "groups = ['pgp1_1', 'pgp1_2', 'astro_1', 'astro_2', 'excite_neuron_1', 'excite_neuron_2']\n",
    "plot_tss_heatmap(adata, groups, groups, 'TCF4', 'figures/tss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "civil-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = sc.read('/Users/fairliereese/mortazavi_lab/data/2021_c2c12/processing/scanpy/sc_tss_raw.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "appreciated-bloom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>ill_umi_count</th>\n",
       "      <th>ill_gene_count</th>\n",
       "      <th>merged_bc</th>\n",
       "      <th>bc3</th>\n",
       "      <th>bc2</th>\n",
       "      <th>bc1</th>\n",
       "      <th>well</th>\n",
       "      <th>primer_type</th>\n",
       "      <th>raw_bc1</th>\n",
       "      <th>n_genes</th>\n",
       "      <th>n_counts</th>\n",
       "      <th>leiden</th>\n",
       "      <th>boi</th>\n",
       "      <th>short_leiden</th>\n",
       "      <th>bc</th>\n",
       "      <th>umap_x</th>\n",
       "      <th>umap_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MB_cells</td>\n",
       "      <td>42834</td>\n",
       "      <td>7600</td>\n",
       "      <td>TGGAACAAGTGTTCTACGTTCGAG</td>\n",
       "      <td>TGGAACAA</td>\n",
       "      <td>GTGTTCTA</td>\n",
       "      <td>CGTTCGAG</td>\n",
       "      <td>5</td>\n",
       "      <td>bc1_dt</td>\n",
       "      <td>CGTTCGAG</td>\n",
       "      <td>2891</td>\n",
       "      <td>5933.0</td>\n",
       "      <td>3</td>\n",
       "      <td>TGGAACAAGTGTTCTACGTTCGAG</td>\n",
       "      <td>3</td>\n",
       "      <td>TGGAACAAGTGTTCTACGTTCGAG</td>\n",
       "      <td>-2.283204</td>\n",
       "      <td>-0.422104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MB_nuclei</td>\n",
       "      <td>16745</td>\n",
       "      <td>5317</td>\n",
       "      <td>GTACGCAATCCGTCTAACGCCGGC</td>\n",
       "      <td>GTACGCAA</td>\n",
       "      <td>TCCGTCTA</td>\n",
       "      <td>ACGCCGGC</td>\n",
       "      <td>20</td>\n",
       "      <td>bc1_dt</td>\n",
       "      <td>ACGCCGGC</td>\n",
       "      <td>731</td>\n",
       "      <td>942.0</td>\n",
       "      <td>2</td>\n",
       "      <td>GTACGCAATCCGTCTAACGCCGGC</td>\n",
       "      <td>2</td>\n",
       "      <td>GTACGCAATCCGTCTAACGCCGGC</td>\n",
       "      <td>1.968965</td>\n",
       "      <td>-2.721179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MB_nuclei</td>\n",
       "      <td>47072</td>\n",
       "      <td>7717</td>\n",
       "      <td>AAGAGATCCCGTGAGAACGCCGGC</td>\n",
       "      <td>AAGAGATC</td>\n",
       "      <td>CCGTGAGA</td>\n",
       "      <td>ACGCCGGC</td>\n",
       "      <td>20</td>\n",
       "      <td>bc1_dt</td>\n",
       "      <td>ACGCCGGC</td>\n",
       "      <td>2304</td>\n",
       "      <td>4077.0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAGAGATCCCGTGAGAACGCCGGC</td>\n",
       "      <td>2</td>\n",
       "      <td>AAGAGATCCCGTGAGAACGCCGGC</td>\n",
       "      <td>0.283894</td>\n",
       "      <td>-0.453544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MT_nuclei</td>\n",
       "      <td>10224</td>\n",
       "      <td>3849</td>\n",
       "      <td>ACTATGCAACACGACCGTGCTAGC</td>\n",
       "      <td>ACTATGCA</td>\n",
       "      <td>ACACGACC</td>\n",
       "      <td>GTGCTAGC</td>\n",
       "      <td>27</td>\n",
       "      <td>bc1_dt</td>\n",
       "      <td>GTGCTAGC</td>\n",
       "      <td>559</td>\n",
       "      <td>708.0</td>\n",
       "      <td>5</td>\n",
       "      <td>ACTATGCAACACGACCGTGCTAGC</td>\n",
       "      <td>5</td>\n",
       "      <td>ACTATGCAACACGACCGTGCTAGC</td>\n",
       "      <td>4.121665</td>\n",
       "      <td>-0.614594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MB_nuclei</td>\n",
       "      <td>56919</td>\n",
       "      <td>5760</td>\n",
       "      <td>CAATGGAACTAAGGTCGTTCAACA</td>\n",
       "      <td>CAATGGAA</td>\n",
       "      <td>CTAAGGTC</td>\n",
       "      <td>GTTCAACA</td>\n",
       "      <td>19</td>\n",
       "      <td>bc1_dt</td>\n",
       "      <td>GTTCAACA</td>\n",
       "      <td>2615</td>\n",
       "      <td>7293.0</td>\n",
       "      <td>1</td>\n",
       "      <td>CAATGGAACTAAGGTCGTTCAACA</td>\n",
       "      <td>2</td>\n",
       "      <td>CAATGGAACTAAGGTCGTTCAACA</td>\n",
       "      <td>-0.548823</td>\n",
       "      <td>-0.244649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample  ill_umi_count  ill_gene_count                 merged_bc  \\\n",
       "0   MB_cells          42834            7600  TGGAACAAGTGTTCTACGTTCGAG   \n",
       "1  MB_nuclei          16745            5317  GTACGCAATCCGTCTAACGCCGGC   \n",
       "2  MB_nuclei          47072            7717  AAGAGATCCCGTGAGAACGCCGGC   \n",
       "3  MT_nuclei          10224            3849  ACTATGCAACACGACCGTGCTAGC   \n",
       "4  MB_nuclei          56919            5760  CAATGGAACTAAGGTCGTTCAACA   \n",
       "\n",
       "        bc3       bc2       bc1  well primer_type   raw_bc1  n_genes  \\\n",
       "0  TGGAACAA  GTGTTCTA  CGTTCGAG     5      bc1_dt  CGTTCGAG     2891   \n",
       "1  GTACGCAA  TCCGTCTA  ACGCCGGC    20      bc1_dt  ACGCCGGC      731   \n",
       "2  AAGAGATC  CCGTGAGA  ACGCCGGC    20      bc1_dt  ACGCCGGC     2304   \n",
       "3  ACTATGCA  ACACGACC  GTGCTAGC    27      bc1_dt  GTGCTAGC      559   \n",
       "4  CAATGGAA  CTAAGGTC  GTTCAACA    19      bc1_dt  GTTCAACA     2615   \n",
       "\n",
       "   n_counts leiden                       boi short_leiden  \\\n",
       "0    5933.0      3  TGGAACAAGTGTTCTACGTTCGAG            3   \n",
       "1     942.0      2  GTACGCAATCCGTCTAACGCCGGC            2   \n",
       "2    4077.0      1  AAGAGATCCCGTGAGAACGCCGGC            2   \n",
       "3     708.0      5  ACTATGCAACACGACCGTGCTAGC            5   \n",
       "4    7293.0      1  CAATGGAACTAAGGTCGTTCAACA            2   \n",
       "\n",
       "                         bc    umap_x    umap_y  \n",
       "0  TGGAACAAGTGTTCTACGTTCGAG -2.283204 -0.422104  \n",
       "1  GTACGCAATCCGTCTAACGCCGGC  1.968965 -2.721179  \n",
       "2  AAGAGATCCCGTGAGAACGCCGGC  0.283894 -0.453544  \n",
       "3  ACTATGCAACACGACCGTGCTAGC  4.121665 -0.614594  \n",
       "4  CAATGGAACTAAGGTCGTTCAACA -0.548823 -0.244649  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "hired-jamaica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_name</th>\n",
       "      <th>old_tss_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tss_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0610009B22Rik_1</th>\n",
       "      <td>0610009B22Rik</td>\n",
       "      <td>m54284U_200901_184453/14945111/ccs_10207_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610010F05Rik_1</th>\n",
       "      <td>0610010F05Rik</td>\n",
       "      <td>m54284U_200901_184453/10029371/ccs_9653_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610010F05Rik_2</th>\n",
       "      <td>0610010F05Rik</td>\n",
       "      <td>m54284U_200901_184453/35325797/ccs_9656_26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610010K14Rik_1</th>\n",
       "      <td>0610010K14Rik</td>\n",
       "      <td>m54284U_200901_184453/93389126/ccs_11468_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610030E20Rik_1</th>\n",
       "      <td>0610030E20Rik</td>\n",
       "      <td>m54284U_200901_184453/152569109/ccs_57629_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gene_name                                   old_tss_id\n",
       "tss_id                                                                     \n",
       "0610009B22Rik_1  0610009B22Rik   m54284U_200901_184453/14945111/ccs_10207_5\n",
       "0610010F05Rik_1  0610010F05Rik    m54284U_200901_184453/10029371/ccs_9653_3\n",
       "0610010F05Rik_2  0610010F05Rik   m54284U_200901_184453/35325797/ccs_9656_26\n",
       "0610010K14Rik_1  0610010K14Rik   m54284U_200901_184453/93389126/ccs_11468_4\n",
       "0610030E20Rik_1  0610030E20Rik  m54284U_200901_184453/152569109/ccs_57629_4"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "greek-stereo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  condition dataset\n",
       "0       NaN     NaN\n",
       "1       NaN     NaN\n",
       "2       NaN     NaN\n",
       "3       NaN     NaN\n",
       "4       NaN     NaN"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "daily-relation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>gene_name</th>\n",
       "      <th>tss_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>A1BG_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A1BG-AS1</td>\n",
       "      <td>A1BG-AS1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>A2M</td>\n",
       "      <td>A2M_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>A4GALT</td>\n",
       "      <td>A4GALT_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>AAAS</td>\n",
       "      <td>AAAS_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0 index gene_name      tss_id\n",
       "0        0     0      A1BG      A1BG_1\n",
       "1        1     1  A1BG-AS1  A1BG-AS1_1\n",
       "2        2     2       A2M       A2M_1\n",
       "3        3     3    A4GALT    A4GALT_1\n",
       "4        4     4      AAAS      AAAS_1"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.var.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-baseball",
   "metadata": {},
   "source": [
    "### Isoform switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "iraqi-mustang",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fairliereese/miniconda3/lib/python3.7/site-packages/pandas/core/frame.py:4303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "Transforming to str index.\n",
      "Transforming to str index.\n"
     ]
    }
   ],
   "source": [
    "pass_list = 'talon/pgp1_pass_list.csv'\n",
    "ab_file = 'talon/pgp1_talon_abundance.tsv'\n",
    "cond_map = {'Astrocytes': ['astro_1', 'astro_2'], \\\n",
    "            'Excitatory neurons': ['excite_neuron_1', 'excite_neuron_2'], \\\n",
    "            'PGP1': ['pgp1_1', 'pgp1_2']}\n",
    "\n",
    "df = pd.read_csv(ab_file, sep='\\t')\n",
    "adata = make_adata(df, cond_map, pass_list=pass_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exempt-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do one test for each pair of conditions\n",
    "tested = []\n",
    "conditions = ['Astrocytes', 'Excitatory neurons', 'PGP1']\n",
    "\n",
    "how = 'iso'\n",
    "for c1 in conditions:\n",
    "    for c2 in conditions: \n",
    "        if (c1, c2) in tested or c1 == c2 or (c2, c1) in tested:\n",
    "            continue\n",
    "        else:\n",
    "            tested.append((c1,c2))\n",
    "        df = get_die(adata, [c1, c2], how=how, rc=10)\n",
    "        fname = '{}_{}_{}_die.tsv'.format(c1, c2, how)\n",
    "        df.to_csv(fname, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "indoor-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "tested = []\n",
    "p = 0.05\n",
    "dpi = 10\n",
    "how = 'iso'\n",
    "conditions = ['Astrocytes', 'Excitatory neurons', 'PGP1']\n",
    "for c1 in conditions:\n",
    "    for c2 in conditions: \n",
    "        if (c1, c2) in tested or c1 == c2 or (c2, c1) in tested:\n",
    "            continue\n",
    "        else:\n",
    "            tested.append((c1,c2))\n",
    "        fname = '{}_{}_{}_die.tsv'.format(c1, c2, how)\n",
    "        df = pd.read_csv(fname, sep='\\t')\n",
    "        df = filter_die_results(df, p, dpi)\n",
    "        fname = '{}_{}_{}_sig_die.tsv'.format(c1, c2, how)\n",
    "        df.to_csv(fname, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "weird-sheriff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph from swan.p loaded\n",
      "\n",
      "Plotting transcripts for ENSG00000161203.13\n",
      "Saving transcript path graph for ENST00000382456.7 as figures/AP2M1_dpi_novel_ENST00000382456.7_path.png\n",
      "Saving transcript path graph for ENCODEHT000422582 as figures/AP2M1_dpi_novel_ENCODEHT000422582_path.png\n",
      "Saving transcript path graph for ENST00000439647.5 as figures/AP2M1_dpi_novel_ENST00000439647.5_path.png\n",
      "Saving transcript path graph for ENST00000461733.5 as figures/AP2M1_dpi_novel_ENST00000461733.5_path.png\n",
      "Saving transcript path graph for ENST00000466598.5 as figures/AP2M1_dpi_novel_ENST00000466598.5_path.png\n",
      "Generating report for ENSG00000161203.13\n",
      "\n",
      "Plotting transcripts for ENSG00000161203.13\n",
      "Saving transcript path graph for ENST00000382456.7 as figures/AP2M1_novel_ENST00000382456.7_path.png\n",
      "Saving transcript path graph for ENCODEHT000422582 as figures/AP2M1_novel_ENCODEHT000422582_path.png\n",
      "Saving transcript path graph for ENST00000439647.5 as figures/AP2M1_novel_ENST00000439647.5_path.png\n",
      "Saving transcript path graph for ENST00000461733.5 as figures/AP2M1_novel_ENST00000461733.5_path.png\n",
      "Saving transcript path graph for ENST00000466598.5 as figures/AP2M1_novel_ENST00000466598.5_path.png\n",
      "Generating report for ENSG00000161203.13\n",
      "\n",
      "Plotting transcripts for ENSG00000198301.11\n",
      "Saving transcript path graph for ENST00000356260.9 as figures/SDAD1_dpi_novel_ENST00000356260.9_path.png\n",
      "Saving transcript path graph for ENST00000395710.5 as figures/SDAD1_dpi_novel_ENST00000395710.5_path.png\n",
      "Generating report for ENSG00000198301.11\n",
      "\n",
      "Plotting transcripts for ENSG00000198301.11\n",
      "Saving transcript path graph for ENST00000356260.9 as figures/SDAD1_novel_ENST00000356260.9_path.png\n",
      "Saving transcript path graph for ENST00000395710.5 as figures/SDAD1_novel_ENST00000395710.5_path.png\n",
      "Generating report for ENSG00000198301.11\n",
      "\n",
      "Plotting transcripts for ENSG00000173692.12\n",
      "Saving transcript path graph for ENST00000308696.10 as figures/PSMD1_dpi_novel_ENST00000308696.10_path.png\n",
      "Saving transcript path graph for ENST00000431051.5 as figures/PSMD1_dpi_novel_ENST00000431051.5_path.png\n",
      "Saving transcript path graph for ENST00000491229.1 as figures/PSMD1_dpi_novel_ENST00000491229.1_path.png\n",
      "Generating report for ENSG00000173692.12\n",
      "\n",
      "Plotting transcripts for ENSG00000173692.12\n",
      "Saving transcript path graph for ENST00000308696.10 as figures/PSMD1_novel_ENST00000308696.10_path.png\n",
      "Saving transcript path graph for ENST00000431051.5 as figures/PSMD1_novel_ENST00000431051.5_path.png\n",
      "Saving transcript path graph for ENST00000491229.1 as figures/PSMD1_novel_ENST00000491229.1_path.png\n",
      "Generating report for ENSG00000173692.12\n",
      "\n",
      "Plotting transcripts for ENSG00000080824.18\n",
      "Saving transcript path graph for ENST00000216281.12 as figures/HSP90AA1_dpi_novel_ENST00000216281.12_path.png\n",
      "Saving transcript path graph for ENST00000334701.11 as figures/HSP90AA1_dpi_novel_ENST00000334701.11_path.png\n",
      "Saving transcript path graph for ENST00000555662.1 as figures/HSP90AA1_dpi_novel_ENST00000555662.1_path.png\n",
      "Generating report for ENSG00000080824.18\n",
      "\n",
      "Plotting transcripts for ENSG00000080824.18\n",
      "Saving transcript path graph for ENST00000216281.12 as figures/HSP90AA1_novel_ENST00000216281.12_path.png\n",
      "Saving transcript path graph for ENST00000334701.11 as figures/HSP90AA1_novel_ENST00000334701.11_path.png\n",
      "Saving transcript path graph for ENST00000555662.1 as figures/HSP90AA1_novel_ENST00000555662.1_path.png\n",
      "Generating report for ENSG00000080824.18\n",
      "\n",
      "Plotting transcripts for ENSG00000004866.20\n",
      "Saving transcript path graph for ENST00000393447.8 as figures/ST7_dpi_novel_ENST00000393447.8_path.png\n",
      "Saving transcript path graph for ENST00000323984.7 as figures/ST7_dpi_novel_ENST00000323984.7_path.png\n",
      "Saving transcript path graph for ENST00000393444.7 as figures/ST7_dpi_novel_ENST00000393444.7_path.png\n",
      "Saving transcript path graph for ENST00000265437.9 as figures/ST7_dpi_novel_ENST00000265437.9_path.png\n",
      "Saving transcript path graph for ENST00000487459.5 as figures/ST7_dpi_novel_ENST00000487459.5_path.png\n",
      "Saving transcript path graph for ENST00000393451.7 as figures/ST7_dpi_novel_ENST00000393451.7_path.png\n",
      "Generating report for ENSG00000004866.20\n",
      "\n",
      "Plotting transcripts for ENSG00000004866.20\n",
      "Saving transcript path graph for ENST00000393447.8 as figures/ST7_novel_ENST00000393447.8_path.png\n",
      "Saving transcript path graph for ENST00000323984.7 as figures/ST7_novel_ENST00000323984.7_path.png\n",
      "Saving transcript path graph for ENST00000393444.7 as figures/ST7_novel_ENST00000393444.7_path.png\n",
      "Saving transcript path graph for ENST00000265437.9 as figures/ST7_novel_ENST00000265437.9_path.png\n",
      "Saving transcript path graph for ENST00000487459.5 as figures/ST7_novel_ENST00000487459.5_path.png\n",
      "Saving transcript path graph for ENST00000393451.7 as figures/ST7_novel_ENST00000393451.7_path.png\n",
      "Generating report for ENSG00000004866.20\n",
      "\n",
      "Plotting transcripts for ENSG00000063978.15\n",
      "Saving transcript path graph for ENCODEHT000231675 as figures/RNF4_dpi_novel_ENCODEHT000231675_path.png\n",
      "Saving transcript path graph for ENCODEHT000231677 as figures/RNF4_dpi_novel_ENCODEHT000231677_path.png\n",
      "Generating report for ENSG00000063978.15\n",
      "\n",
      "Plotting transcripts for ENSG00000063978.15\n",
      "Saving transcript path graph for ENCODEHT000231675 as figures/RNF4_novel_ENCODEHT000231675_path.png\n",
      "Saving transcript path graph for ENCODEHT000231677 as figures/RNF4_novel_ENCODEHT000231677_path.png\n",
      "Generating report for ENSG00000063978.15\n",
      "\n",
      "Plotting transcripts for ENSG00000173692.12\n",
      "Saving transcript path graph for ENST00000308696.10 as figures/PSMD1_dpi_novel_ENST00000308696.10_path.png\n",
      "Saving transcript path graph for ENST00000431051.5 as figures/PSMD1_dpi_novel_ENST00000431051.5_path.png\n",
      "Saving transcript path graph for ENST00000491229.1 as figures/PSMD1_dpi_novel_ENST00000491229.1_path.png\n",
      "Generating report for ENSG00000173692.12\n",
      "\n",
      "Plotting transcripts for ENSG00000173692.12\n",
      "Saving transcript path graph for ENST00000308696.10 as figures/PSMD1_novel_ENST00000308696.10_path.png\n",
      "Saving transcript path graph for ENST00000431051.5 as figures/PSMD1_novel_ENST00000431051.5_path.png\n",
      "Saving transcript path graph for ENST00000491229.1 as figures/PSMD1_novel_ENST00000491229.1_path.png\n",
      "Generating report for ENSG00000173692.12\n",
      "\n",
      "Plotting transcripts for ENSG00000161203.13\n",
      "Saving transcript path graph for ENST00000382456.7 as figures/AP2M1_dpi_novel_ENST00000382456.7_path.png\n",
      "Saving transcript path graph for ENCODEHT000422582 as figures/AP2M1_dpi_novel_ENCODEHT000422582_path.png\n",
      "Saving transcript path graph for ENST00000439647.5 as figures/AP2M1_dpi_novel_ENST00000439647.5_path.png\n",
      "Saving transcript path graph for ENST00000461733.5 as figures/AP2M1_dpi_novel_ENST00000461733.5_path.png\n",
      "Saving transcript path graph for ENST00000466598.5 as figures/AP2M1_dpi_novel_ENST00000466598.5_path.png\n",
      "Generating report for ENSG00000161203.13\n",
      "\n",
      "Plotting transcripts for ENSG00000161203.13\n",
      "Saving transcript path graph for ENST00000382456.7 as figures/AP2M1_novel_ENST00000382456.7_path.png\n",
      "Saving transcript path graph for ENCODEHT000422582 as figures/AP2M1_novel_ENCODEHT000422582_path.png\n",
      "Saving transcript path graph for ENST00000439647.5 as figures/AP2M1_novel_ENST00000439647.5_path.png\n",
      "Saving transcript path graph for ENST00000461733.5 as figures/AP2M1_novel_ENST00000461733.5_path.png\n",
      "Saving transcript path graph for ENST00000466598.5 as figures/AP2M1_novel_ENST00000466598.5_path.png\n",
      "Generating report for ENSG00000161203.13\n",
      "\n",
      "Plotting transcripts for ENSG00000213445.9\n",
      "Saving transcript path graph for ENST00000534313.5 as figures/SIPA1_dpi_novel_ENST00000534313.5_path.png\n",
      "Saving transcript path graph for ENST00000528699.1 as figures/SIPA1_dpi_novel_ENST00000528699.1_path.png\n",
      "Generating report for ENSG00000213445.9\n",
      "\n",
      "Plotting transcripts for ENSG00000213445.9\n",
      "Saving transcript path graph for ENST00000534313.5 as figures/SIPA1_novel_ENST00000534313.5_path.png\n",
      "Saving transcript path graph for ENST00000528699.1 as figures/SIPA1_novel_ENST00000528699.1_path.png\n",
      "Generating report for ENSG00000213445.9\n",
      "\n",
      "Plotting transcripts for ENSG00000160113.5\n",
      "Saving transcript path graph for ENST00000291442.3 as figures/NR2F6_dpi_novel_ENST00000291442.3_path.png\n",
      "Generating report for ENSG00000160113.5\n",
      "\n",
      "Plotting transcripts for ENSG00000160113.5\n",
      "Saving transcript path graph for ENST00000291442.3 as figures/NR2F6_novel_ENST00000291442.3_path.png\n",
      "Generating report for ENSG00000160113.5\n",
      "\n",
      "Plotting transcripts for ENSG00000106554.12\n",
      "Saving transcript path graph for ENST00000262570.9 as figures/CHCHD3_dpi_novel_ENST00000262570.9_path.png\n",
      "Saving transcript path graph for ENCODEHT000395106 as figures/CHCHD3_dpi_novel_ENCODEHT000395106_path.png\n",
      "Saving transcript path graph for ENST00000448878.6 as figures/CHCHD3_dpi_novel_ENST00000448878.6_path.png\n",
      "Generating report for ENSG00000106554.12\n",
      "\n",
      "Plotting transcripts for ENSG00000106554.12\n",
      "Saving transcript path graph for ENST00000262570.9 as figures/CHCHD3_novel_ENST00000262570.9_path.png\n",
      "Saving transcript path graph for ENCODEHT000395106 as figures/CHCHD3_novel_ENCODEHT000395106_path.png\n",
      "Saving transcript path graph for ENST00000448878.6 as figures/CHCHD3_novel_ENST00000448878.6_path.png\n",
      "Generating report for ENSG00000106554.12\n",
      "\n",
      "Plotting transcripts for ENSG00000101150.17\n",
      "Saving transcript path graph for ENST00000346249.8 as figures/TPD52L2_dpi_novel_ENST00000346249.8_path.png\n",
      "Saving transcript path graph for ENST00000348257.9 as figures/TPD52L2_dpi_novel_ENST00000348257.9_path.png\n",
      "Saving transcript path graph for ENST00000358548.4 as figures/TPD52L2_dpi_novel_ENST00000358548.4_path.png\n",
      "Saving transcript path graph for ENST00000352482.8 as figures/TPD52L2_dpi_novel_ENST00000352482.8_path.png\n",
      "Saving transcript path graph for ENST00000217121.9 as figures/TPD52L2_dpi_novel_ENST00000217121.9_path.png\n",
      "Saving transcript path graph for ENST00000351424.8 as figures/TPD52L2_dpi_novel_ENST00000351424.8_path.png\n",
      "Saving transcript path graph for ENST00000474176.2 as figures/TPD52L2_dpi_novel_ENST00000474176.2_path.png\n",
      "Generating report for ENSG00000101150.17\n",
      "\n",
      "Plotting transcripts for ENSG00000101150.17\n",
      "Saving transcript path graph for ENST00000346249.8 as figures/TPD52L2_novel_ENST00000346249.8_path.png\n",
      "Saving transcript path graph for ENST00000348257.9 as figures/TPD52L2_novel_ENST00000348257.9_path.png\n",
      "Saving transcript path graph for ENST00000358548.4 as figures/TPD52L2_novel_ENST00000358548.4_path.png\n",
      "Saving transcript path graph for ENST00000352482.8 as figures/TPD52L2_novel_ENST00000352482.8_path.png\n",
      "Saving transcript path graph for ENST00000217121.9 as figures/TPD52L2_novel_ENST00000217121.9_path.png\n",
      "Saving transcript path graph for ENST00000351424.8 as figures/TPD52L2_novel_ENST00000351424.8_path.png\n",
      "Saving transcript path graph for ENST00000474176.2 as figures/TPD52L2_novel_ENST00000474176.2_path.png\n",
      "Generating report for ENSG00000101150.17\n",
      "\n",
      "Plotting transcripts for ENSG00000197746.13\n",
      "Saving transcript path graph for ENST00000394936.7 as figures/PSAP_dpi_novel_ENST00000394936.7_path.png\n",
      "Saving transcript path graph for ENCODEHT000223155 as figures/PSAP_dpi_novel_ENCODEHT000223155_path.png\n",
      "Saving transcript path graph for ENST00000394934.4 as figures/PSAP_dpi_novel_ENST00000394934.4_path.png\n",
      "Generating report for ENSG00000197746.13\n",
      "\n",
      "Plotting transcripts for ENSG00000197746.13\n",
      "Saving transcript path graph for ENST00000394936.7 as figures/PSAP_novel_ENST00000394936.7_path.png\n",
      "Saving transcript path graph for ENCODEHT000223155 as figures/PSAP_novel_ENCODEHT000223155_path.png\n",
      "Saving transcript path graph for ENST00000394934.4 as figures/PSAP_novel_ENST00000394934.4_path.png\n",
      "Generating report for ENSG00000197746.13\n",
      "\n",
      "Plotting transcripts for ENSG00000198467.14\n",
      "Saving transcript path graph for ENST00000378292.8 as figures/TPM2_dpi_novel_ENST00000378292.8_path.png\n",
      "Saving transcript path graph for ENST00000329305.6 as figures/TPM2_dpi_novel_ENST00000329305.6_path.png\n",
      "Saving transcript path graph for ENST00000645482.1 as figures/TPM2_dpi_novel_ENST00000645482.1_path.png\n",
      "Saving transcript path graph for ENST00000647435.1 as figures/TPM2_dpi_novel_ENST00000647435.1_path.png\n",
      "Saving transcript path graph for ENCODEHT000330128 as figures/TPM2_dpi_novel_ENCODEHT000330128_path.png\n",
      "Saving transcript path graph for ENCODEHT000330119 as figures/TPM2_dpi_novel_ENCODEHT000330119_path.png\n",
      "Saving transcript path graph for ENCODEHT000330339 as figures/TPM2_dpi_novel_ENCODEHT000330339_path.png\n",
      "Saving transcript path graph for ENST00000471212.5 as figures/TPM2_dpi_novel_ENST00000471212.5_path.png\n",
      "Generating report for ENSG00000198467.14\n",
      "\n",
      "Plotting transcripts for ENSG00000198467.14\n",
      "Saving transcript path graph for ENST00000378292.8 as figures/TPM2_novel_ENST00000378292.8_path.png\n",
      "Saving transcript path graph for ENST00000329305.6 as figures/TPM2_novel_ENST00000329305.6_path.png\n",
      "Saving transcript path graph for ENST00000645482.1 as figures/TPM2_novel_ENST00000645482.1_path.png\n",
      "Saving transcript path graph for ENST00000647435.1 as figures/TPM2_novel_ENST00000647435.1_path.png\n",
      "Saving transcript path graph for ENCODEHT000330128 as figures/TPM2_novel_ENCODEHT000330128_path.png\n",
      "Saving transcript path graph for ENCODEHT000330119 as figures/TPM2_novel_ENCODEHT000330119_path.png\n",
      "Saving transcript path graph for ENCODEHT000330339 as figures/TPM2_novel_ENCODEHT000330339_path.png\n",
      "Saving transcript path graph for ENST00000471212.5 as figures/TPM2_novel_ENST00000471212.5_path.png\n",
      "Generating report for ENSG00000198467.14\n",
      "\n",
      "Plotting transcripts for ENSG00000100321.14\n",
      "Saving transcript path graph for ENST00000318801.8 as figures/SYNGR1_dpi_novel_ENST00000318801.8_path.png\n",
      "Saving transcript path graph for ENST00000328933.9 as figures/SYNGR1_dpi_novel_ENST00000328933.9_path.png\n",
      "Saving transcript path graph for ENST00000489206.1 as figures/SYNGR1_dpi_novel_ENST00000489206.1_path.png\n",
      "Generating report for ENSG00000100321.14\n",
      "\n",
      "Plotting transcripts for ENSG00000100321.14\n",
      "Saving transcript path graph for ENST00000318801.8 as figures/SYNGR1_novel_ENST00000318801.8_path.png\n",
      "Saving transcript path graph for ENST00000328933.9 as figures/SYNGR1_novel_ENST00000328933.9_path.png\n",
      "Saving transcript path graph for ENST00000489206.1 as figures/SYNGR1_novel_ENST00000489206.1_path.png\n",
      "Generating report for ENSG00000100321.14\n"
     ]
    }
   ],
   "source": [
    "# make some swan reports of DIE isos \n",
    "\n",
    "# look at top significant ones and splicing factors\n",
    "sg = swan.SwanGraph('swan.p')\n",
    "\n",
    "tested = []\n",
    "\n",
    "how = 'iso'\n",
    "conditions = ['Astrocytes', 'Excitatory neurons', 'PGP1']\n",
    "for c1 in conditions:\n",
    "    for c2 in conditions: \n",
    "        if (c1, c2) in tested or c1 == c2 or (c2, c1) in tested:\n",
    "            continue\n",
    "        else:\n",
    "            tested.append((c1,c2))\n",
    "        fname = '{}_{}_{}_sig_die.tsv'.format(c1, c2, how)\n",
    "        df = pd.read_csv(fname, sep='\\t')\n",
    "        \n",
    "        # sort by dpi\n",
    "        df = df.sort_values(by='dpi', ascending=False)\n",
    "        for gname in df['index'].tolist()[:5]:\n",
    "            \n",
    "            # dpi swangraph\n",
    "            sg.gen_report(gname, prefix='figures/{}_dpi'.format(gname),\n",
    "                heatmap=True, \n",
    "                dpi=True, \n",
    "                cmap='magma', \n",
    "                indicate_novel=True,\n",
    "                novelty=True)\n",
    "            \n",
    "            # tpm swangraph\n",
    "            sg.gen_report(gname, prefix='figures/{}'.format(gname),\n",
    "                heatmap=True, \n",
    "                cmap='viridis', \n",
    "                indicate_novel=True,\n",
    "                novelty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "white-recipe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plotting transcripts for ENSG00000161547.16\n",
      "Saving transcript path graph for ENST00000359995.9 as figures/SRSF2_dpi_novel_ENST00000359995.9_path.png\n",
      "Saving transcript path graph for ENST00000392485.2 as figures/SRSF2_dpi_novel_ENST00000392485.2_path.png\n",
      "Saving transcript path graph for ENST00000585202.5 as figures/SRSF2_dpi_novel_ENST00000585202.5_path.png\n",
      "Saving transcript path graph for ENST00000452355.7 as figures/SRSF2_dpi_novel_ENST00000452355.7_path.png\n",
      "Saving transcript path graph for ENST00000586778.1 as figures/SRSF2_dpi_novel_ENST00000586778.1_path.png\n",
      "Saving transcript path graph for ENST00000582449.5 as figures/SRSF2_dpi_novel_ENST00000582449.5_path.png\n",
      "Generating report for ENSG00000161547.16\n",
      "\n",
      "Plotting transcripts for ENSG00000161547.16\n",
      "Saving transcript path graph for ENST00000359995.9 as figures/SRSF2_novel_ENST00000359995.9_path.png\n",
      "Saving transcript path graph for ENST00000392485.2 as figures/SRSF2_novel_ENST00000392485.2_path.png\n",
      "Saving transcript path graph for ENST00000585202.5 as figures/SRSF2_novel_ENST00000585202.5_path.png\n",
      "Saving transcript path graph for ENST00000452355.7 as figures/SRSF2_novel_ENST00000452355.7_path.png\n",
      "Saving transcript path graph for ENST00000586778.1 as figures/SRSF2_novel_ENST00000586778.1_path.png\n",
      "Saving transcript path graph for ENST00000582449.5 as figures/SRSF2_novel_ENST00000582449.5_path.png\n",
      "Generating report for ENSG00000161547.16\n",
      "\n",
      "Plotting transcripts for ENSG00000112081.16\n",
      "Saving transcript path graph for ENST00000373715.10 as figures/SRSF3_dpi_novel_ENST00000373715.10_path.png\n",
      "Saving transcript path graph for ENST00000477442.6 as figures/SRSF3_dpi_novel_ENST00000477442.6_path.png\n",
      "Saving transcript path graph for ENST00000620389.1 as figures/SRSF3_dpi_novel_ENST00000620389.1_path.png\n",
      "Saving transcript path graph for ENST00000614136.1 as figures/SRSF3_dpi_novel_ENST00000614136.1_path.png\n",
      "Saving transcript path graph for ENST00000339436.11 as figures/SRSF3_dpi_novel_ENST00000339436.11_path.png\n",
      "Generating report for ENSG00000112081.16\n",
      "\n",
      "Plotting transcripts for ENSG00000112081.16\n",
      "Saving transcript path graph for ENST00000373715.10 as figures/SRSF3_novel_ENST00000373715.10_path.png\n",
      "Saving transcript path graph for ENST00000477442.6 as figures/SRSF3_novel_ENST00000477442.6_path.png\n",
      "Saving transcript path graph for ENST00000620389.1 as figures/SRSF3_novel_ENST00000620389.1_path.png\n",
      "Saving transcript path graph for ENST00000614136.1 as figures/SRSF3_novel_ENST00000614136.1_path.png\n",
      "Saving transcript path graph for ENST00000339436.11 as figures/SRSF3_novel_ENST00000339436.11_path.png\n",
      "Generating report for ENSG00000112081.16\n",
      "\n",
      "Plotting transcripts for ENSG00000115875.18\n",
      "Saving transcript path graph for ENST00000313117.10 as figures/SRSF7_dpi_novel_ENST00000313117.10_path.png\n",
      "Saving transcript path graph for ENST00000446327.6 as figures/SRSF7_dpi_novel_ENST00000446327.6_path.png\n",
      "Saving transcript path graph for ENST00000443213.5 as figures/SRSF7_dpi_novel_ENST00000443213.5_path.png\n",
      "Saving transcript path graph for ENST00000409276.5 as figures/SRSF7_dpi_novel_ENST00000409276.5_path.png\n",
      "Saving transcript path graph for ENST00000425778.5 as figures/SRSF7_dpi_novel_ENST00000425778.5_path.png\n",
      "Saving transcript path graph for ENST00000431066.5 as figures/SRSF7_dpi_novel_ENST00000431066.5_path.png\n",
      "Saving transcript path graph for ENST00000477635.5 as figures/SRSF7_dpi_novel_ENST00000477635.5_path.png\n",
      "Generating report for ENSG00000115875.18\n",
      "\n",
      "Plotting transcripts for ENSG00000115875.18\n",
      "Saving transcript path graph for ENST00000313117.10 as figures/SRSF7_novel_ENST00000313117.10_path.png\n",
      "Saving transcript path graph for ENST00000446327.6 as figures/SRSF7_novel_ENST00000446327.6_path.png\n",
      "Saving transcript path graph for ENST00000443213.5 as figures/SRSF7_novel_ENST00000443213.5_path.png\n",
      "Saving transcript path graph for ENST00000409276.5 as figures/SRSF7_novel_ENST00000409276.5_path.png\n",
      "Saving transcript path graph for ENST00000425778.5 as figures/SRSF7_novel_ENST00000425778.5_path.png\n",
      "Saving transcript path graph for ENST00000431066.5 as figures/SRSF7_novel_ENST00000431066.5_path.png\n",
      "Saving transcript path graph for ENST00000477635.5 as figures/SRSF7_novel_ENST00000477635.5_path.png\n",
      "Generating report for ENSG00000115875.18\n",
      "\n",
      "Plotting transcripts for ENSG00000263465.4\n",
      "Saving transcript path graph for ENST00000587424.2 as figures/SRSF8_dpi_novel_ENST00000587424.2_path.png\n",
      "Saving transcript path graph for ENST00000638426.1 as figures/SRSF8_dpi_novel_ENST00000638426.1_path.png\n",
      "Generating report for ENSG00000263465.4\n",
      "\n",
      "Plotting transcripts for ENSG00000263465.4\n",
      "Saving transcript path graph for ENST00000587424.2 as figures/SRSF8_novel_ENST00000587424.2_path.png\n",
      "Saving transcript path graph for ENST00000638426.1 as figures/SRSF8_novel_ENST00000638426.1_path.png\n",
      "Generating report for ENSG00000263465.4\n",
      "\n",
      "Plotting transcripts for ENSG00000116754.13\n",
      "Saving transcript path graph for ENCODEHT000416717 as figures/SRSF11_dpi_novel_ENCODEHT000416717_path.png\n",
      "Saving transcript path graph for ENST00000370950.7 as figures/SRSF11_dpi_novel_ENST00000370950.7_path.png\n",
      "Saving transcript path graph for ENST00000370951.5 as figures/SRSF11_dpi_novel_ENST00000370951.5_path.png\n",
      "Saving transcript path graph for ENST00000370949.1 as figures/SRSF11_dpi_novel_ENST00000370949.1_path.png\n",
      "Saving transcript path graph for ENST00000489188.1 as figures/SRSF11_dpi_novel_ENST00000489188.1_path.png\n",
      "Saving transcript path graph for ENST00000463877.1 as figures/SRSF11_dpi_novel_ENST00000463877.1_path.png\n",
      "Saving transcript path graph for ENST00000460795.5 as figures/SRSF11_dpi_novel_ENST00000460795.5_path.png\n",
      "Saving transcript path graph for ENST00000461935.1 as figures/SRSF11_dpi_novel_ENST00000461935.1_path.png\n",
      "Saving transcript path graph for ENST00000484162.5 as figures/SRSF11_dpi_novel_ENST00000484162.5_path.png\n",
      "Generating report for ENSG00000116754.13\n",
      "\n",
      "Plotting transcripts for ENSG00000116754.13\n",
      "Saving transcript path graph for ENCODEHT000416717 as figures/SRSF11_novel_ENCODEHT000416717_path.png\n",
      "Saving transcript path graph for ENST00000370950.7 as figures/SRSF11_novel_ENST00000370950.7_path.png\n",
      "Saving transcript path graph for ENST00000370951.5 as figures/SRSF11_novel_ENST00000370951.5_path.png\n",
      "Saving transcript path graph for ENST00000370949.1 as figures/SRSF11_novel_ENST00000370949.1_path.png\n",
      "Saving transcript path graph for ENST00000489188.1 as figures/SRSF11_novel_ENST00000489188.1_path.png\n",
      "Saving transcript path graph for ENST00000463877.1 as figures/SRSF11_novel_ENST00000463877.1_path.png\n",
      "Saving transcript path graph for ENST00000460795.5 as figures/SRSF11_novel_ENST00000460795.5_path.png\n",
      "Saving transcript path graph for ENST00000461935.1 as figures/SRSF11_novel_ENST00000461935.1_path.png\n",
      "Saving transcript path graph for ENST00000484162.5 as figures/SRSF11_novel_ENST00000484162.5_path.png\n",
      "Generating report for ENSG00000116754.13\n"
     ]
    }
   ],
   "source": [
    "# splicing factors\n",
    "gnames = ['SRSF2', 'SRSF3', 'SRSF7', 'SRSF8', 'SRSF11']\n",
    "\n",
    "for gname in gnames:\n",
    "    # dpi swangraph\n",
    "    sg.gen_report(gname, prefix='figures/{}_dpi'.format(gname),\n",
    "        heatmap=True, \n",
    "        dpi=True, \n",
    "        cmap='magma', \n",
    "        indicate_novel=True,\n",
    "        novelty=True)\n",
    "\n",
    "    # tpm swangraph\n",
    "    sg.gen_report(gname, prefix='figures/{}'.format(gname),\n",
    "        heatmap=True, \n",
    "        cmap='viridis', \n",
    "        indicate_novel=True,\n",
    "        novelty=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-shoulder",
   "metadata": {},
   "source": [
    "### Genome browser track to color reads by their sample of origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-digit",
   "metadata": {},
   "source": [
    "```bash\n",
    "module load samtools\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "median-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shlex\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "def make_bam_hub_entry(df, c_dict, ofile):\n",
    "    with open(ofile, 'w') as o:\n",
    "        for ind, e in df.iterrows():\n",
    "            c = c_dict[e['sample']]\n",
    "            c = c.lstrip('#')\n",
    "            c = tuple(int(c[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "            s = 'track {}_reads\\n'.format(e['sample'])\n",
    "            s += 'bigDataUrl {}\\n'.format(e.url)\n",
    "            s += 'shortLabel {}_reads\\n'.format(e['sample'])\n",
    "            s += 'longLabel {}_reads\\n'.format(e['sample'])\n",
    "            s += 'type bam\\n'\n",
    "            s += 'visibility squish\\n'\n",
    "            s += 'bamColorMode off\\n'\n",
    "            s += 'color {},{},{}\\n\\n'.format(c[0],c[1],c[2])\n",
    "            o.write(s)\n",
    "\n",
    "# \"input\"\n",
    "url = 'http://crick.bio.uci.edu/freese/210413_pgp1_hub/'\n",
    "c_dict = {'astro_1': '#f6ef7c', 'astro_2': '#eabc68',\\\n",
    "          'excite_neuron_1': '#e4d3cd', 'excite_neuron_2': '#d3a8b2',\\\n",
    "          'pgp1_1': '#bef4ff', 'pgp1_2': '#73a8b2'}\n",
    "config = 'talon/config.csv'\n",
    "genome = 'hg38'\n",
    "hub_name = 'pgp1'\n",
    "email = 'freese@uci.edu'\n",
    "scp_location = 'freese@crick.bio.uci.edu:~/pub/210413_pgp1_hub/'\n",
    "\n",
    "\n",
    "genomefile = 'hub/genomes.txt'\n",
    "hubfile = 'hub/hub.txt'\n",
    "hubfile_relative = 'hub.txt'\n",
    "trackdb = 'hub/{}/trackDb.txt'.format(genome)\n",
    "relative_trackdb = '{}/trackDb.txt'.format(genome)\n",
    "relative_genome = 'genomes.txt'\n",
    "try:\n",
    "    os.makedirs(os.path.dirname(trackdb))\n",
    "except:\n",
    "    pass\n",
    "df = pd.read_csv(config, header=None, names=['sample', 'condition', \\\n",
    "                                             'platform', 'filepath'])\n",
    "df['url'] = df.apply(lambda x: url+x['sample']+'.bam', axis=1)\n",
    "df['local_loc'] = df.apply(lambda x: 'talon_tmp/'+x['sample']+'.bam', axis=1)\n",
    "\n",
    "for ind, entry in df.iterrows():\n",
    "    cmd = 'samtools index {}'.format(entry.local_loc)\n",
    "    print(cmd)\n",
    "    cmd = shlex.split(cmd)\n",
    "    result = subprocess.run(cmd)  \n",
    "    \n",
    "    cmd = 'scp {} {}'.format(entry.local_loc, scp_location)\n",
    "    cmd = shlex.split(cmd)\n",
    "    print(cmd)\n",
    "    result = subprocess.run(cmd)\n",
    "    \n",
    "    cmd = 'scp {}.bai {}'.format(entry.local_loc, scp_location)\n",
    "    cmd = shlex.split(cmd)\n",
    "    print(cmd)\n",
    "    result = subprocess.run(cmd)\n",
    "    \n",
    "    \n",
    "make_bam_hub_entry(df, c_dict, trackdb)\n",
    "\n",
    "with open(genomefile, 'w') as o:\n",
    "    s = 'genome {}\\n'.format(genome)\n",
    "    s += 'trackDb {}\\n'.format(relative_trackdb)\n",
    "    o.write(s)\n",
    "\n",
    "with open(hubfile, 'w') as o:\n",
    "    s = 'hub {}\\n'.format(hub_name)\n",
    "    s += 'shortLabel {}\\n'.format(hub_name)\n",
    "    s += 'longLabel {}\\n'.format(hub_name)\n",
    "    s += 'genomesFile {}\\n'.format(relative_genome)\n",
    "    s += 'email {}\\n'.format(email)\n",
    "    o.write(s)\n",
    "\n",
    "cmd = 'scp -r hub/* {}'.format(scp_location)\n",
    "cmd = shlex.split(cmd)\n",
    "result = subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-section",
   "metadata": {},
   "source": [
    "```bash\n",
    "scp -r hub/ freese@crick.bio.uci.edu:~/pub/210413_pgp1_hub/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-translator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
